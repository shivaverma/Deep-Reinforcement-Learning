{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: AgentBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"../../tennis/Tennis\", worker_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Number of actions: 2\n",
      "Observations have length: 24\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      "  0.          0.         -6.83172083  6.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)\n",
    "\n",
    "# number of agents in the environment\n",
    "num_agents = len(env_info[brain_name].agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the observation space \n",
    "states = env_info[brain_name].vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('Observations have length:', state_size)\n",
    "print(states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_episode in range(10):\n",
    "    # initialize environment, get initial states\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    states = env_info.vector_observations\n",
    "    scores = np.zeros(num_agents)\n",
    "    while True:\n",
    "        # select action (for each agent)\n",
    "        actions = np.random.randn(num_agents, action_size)\n",
    "        # take action (for each agent)\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        next_states = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        dones = env_info.local_done\n",
    "        # assign new state and update score (for each agent)\n",
    "        states = next_states\n",
    "        scores += env_info.rewards\n",
    "        if np.any(dones):\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tScores:[-0.01  0.  ]\tAvg Scores: 0.0\n",
      "Episode 200\tScores:[-0.01  0.  ]\tAvg Scores: 0.017700000293552877\n",
      "Episode 300\tScores:[-0.01  0.  ]\tAvg Scores: 0.021900000348687172\n",
      "Episode 400\tScores:[ 0.   -0.01]\tAvg Scores: 0.006000000089406967\n",
      "Episode 500\tScores:[ 0.1  -0.01]\tAvg Scores: 0.0010000000149011613\n",
      "Episode 600\tScores:[ 0.   -0.01]\tAvg Scores: 0.041900000628083946\n",
      "Episode 700\tScores:[-0.01  0.  ]\tAvg Scores: 0.0010000000149011613\n",
      "Episode 800\tScores:[-0.01  0.  ]\tAvg Scores: 0.0010000000149011613\n",
      "Episode 900\tScores:[-0.01  0.  ]\tAvg Scores: 0.004800000116229057\n",
      "Episode 1000\tScores:[-0.01  0.  ]\tAvg Scores: 0.05500000081956387\n",
      "Episode 1100\tScores:[ 0.   -0.01]\tAvg Scores: 0.0\n",
      "Episode 1200\tScores:[-0.01  0.  ]\tAvg Scores: 0.0\n",
      "Episode 1300\tScores:[-0.01  0.  ]\tAvg Scores: 0.0\n",
      "Episode 1400\tScores:[0.19 0.2 ]\tAvg Scores: 0.04050000062212348\n",
      "Episode 1500\tScores:[-0.01  0.1 ]\tAvg Scores: 0.0559000008367002\n",
      "Episode 1600\tScores:[ 0.   -0.01]\tAvg Scores: 0.027000000402331352\n",
      "Episode 1700\tScores:[ 0.1  -0.01]\tAvg Scores: 0.09720000149682165\n",
      "Episode 1800\tScores:[-0.01  0.1 ]\tAvg Scores: 0.07070000112056732\n",
      "Episode 1900\tScores:[-0.01  0.  ]\tAvg Scores: 0.09900000151246786\n",
      "Episode 2000\tScores:[ 0.   -0.01]\tAvg Scores: 0.04810000078752637\n",
      "Episode 2100\tScores:[-0.01  0.1 ]\tAvg Scores: 0.3353000050224364\n",
      "Episode 2200\tScores:[0.09 0.  ]\tAvg Scores: 0.17480000264942647\n",
      "Episode 2300\tScores:[ 0.1  -0.01]\tAvg Scores: 0.020800000317394735\n",
      "Episode 2400\tScores:[-0.01  0.1 ]\tAvg Scores: 0.0865000013075769\n",
      "Episode 2500\tScores:[0.09 0.2 ]\tAvg Scores: 0.19370000291615724\n",
      "Episode 2600\tScores:[-0.01  0.1 ]\tAvg Scores: 0.155500002335757\n",
      "Episode 2700\tScores:[ 0.1  -0.01]\tAvg Scores: 0.13510000206530093\n",
      "Episode 2800\tScores:[0.2  0.09]\tAvg Scores: 0.13630000207573176\n",
      "Episode 2900\tScores:[0.1  0.09]\tAvg Scores: 0.2470000036805868\n",
      "Episode 3000\tScores:[0.3  0.19]\tAvg Scores: 0.27770000414922835\n",
      "Episode 3100\tScores:[0.19 0.2 ]\tAvg Scores: 0.3916000058874488\n",
      "Episode 3200\tScores:[-0.01  0.  ]\tAvg Scores: 0.6042000090330839\n",
      "Episode 3300\tScores:[1.49000002 1.60000002]\tAvg Scores: 0.6102000091411174\n",
      "Episode 3400\tScores:[0.80000001 0.69000001]\tAvg Scores: 0.5778000086173415\n",
      "Episode 3500\tScores:[0.19 0.3 ]\tAvg Scores: 0.5039000075310469\n",
      "Episode 3600\tScores:[0.90000001 0.79000001]\tAvg Scores: 0.5717000085860491\n",
      "Episode 3700\tScores:[0.29 0.3 ]\tAvg Scores: 0.6477000096999109\n",
      "Episode 3800\tScores:[1.00000001 0.89000001]\tAvg Scores: 0.7676000114716589\n",
      "Episode 3900\tScores:[0.89000001 1.00000001]\tAvg Scores: 0.791500011831522\n",
      "Episode 4000\tScores:[2.19000003 2.20000003]\tAvg Scores: 0.7394000110775232\n",
      "Episode 4100\tScores:[0.29 0.3 ]\tAvg Scores: 0.41900000628083944\n",
      "Episode 4200\tScores:[0.1  0.09]\tAvg Scores: 0.3186000048369169\n",
      "Episode 4300\tScores:[1.30000002 1.29000002]\tAvg Scores: 0.49450000740587713\n",
      "Episode 4400\tScores:[0.59000001 0.60000001]\tAvg Scores: 0.6385000095888972\n",
      "Episode 4500\tScores:[ 0.1  -0.01]\tAvg Scores: 0.5291000079363585\n",
      "Episode 4600\tScores:[0.50000001 0.39000001]\tAvg Scores: 0.8321000124327839\n",
      "Episode 4700\tScores:[0.29       0.40000001]\tAvg Scores: 0.6758000101521611\n",
      "Episode 4800\tScores:[-0.01  0.  ]\tAvg Scores: 0.4368000065721571\n",
      "Episode 4900\tScores:[ 0.   -0.01]\tAvg Scores: 0.2798000042326748\n",
      "Episode 5000\tScores:[0.3  0.19]\tAvg Scores: 0.2556000038795173\n",
      "Episode 5100\tScores:[1.69000003 1.80000003]\tAvg Scores: 0.6682000100240111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "\n",
      "ERROR:unityagents:An error might have occured in the environment. You can check the logfile for more information at /Users/alexis.cook/Desktop/tennis/unity-environment.log\n"
     ]
    },
    {
     "ename": "UnityTimeOutException",
     "evalue": "The environment took too long to respond.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0mmessage_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mtimeout\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnityTimeOutException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8458ae81bfed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\"STEP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m_get_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_of_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mend_of_message\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_of_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m_get_state_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \"\"\"\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"END_OF_MESSAGE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'True'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The environment took too long to respond.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityTimeOutException\u001b[0m: The environment took too long to respond."
     ]
    }
   ],
   "source": [
    "num_episodes = 10000\n",
    "print_every = 100\n",
    "\n",
    "# initialize the agent\n",
    "agent = Agent(state_size, action_size)\n",
    "\n",
    "scores = deque(maxlen=100)\n",
    "all_scores = []\n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    agent.reset()\n",
    "    score = np.zeros(num_agents)\n",
    "    actions = np.zeros((num_agents, action_size))\n",
    "    while True:\n",
    "        states = env_info.vector_observations\n",
    "        for i in range(num_agents):\n",
    "            actions[i] = agent.act(states[i])\n",
    "            agent.learn_i()\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        agent.step(states, env_info)\n",
    "        score += env_info.rewards\n",
    "        if env_info.local_done[0]:\n",
    "            scores.append(np.max(score))\n",
    "            all_scores.append(np.max(score))\n",
    "            break\n",
    "        \n",
    "    if i_episode % print_every == 0:\n",
    "        print('Episode {}\\tScores:{}\\tAvg Scores: {}'.format(i_episode, score, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot the Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126de1a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(all_scores)+1), all_scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('scores', 'wb') as fp:\n",
    "    pickle.dump(all_scores, fp)\n",
    "    \n",
    "#with open('scores', 'rb') as fp:\n",
    "#    all_scores = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Watch a Smart Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = UnityEnvironment(file_name=\"../../ml-agents/python/Banana-vector-Mac.app\", worker_id=2)\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "score = 0\n",
    "while True:\n",
    "    state = env_info.vector_observations[0]\n",
    "    action = agent.act(state, eps=0)\n",
    "    env_info = env.step(action+1)[brain_name]\n",
    "    score += env_info.rewards[0]\n",
    "    if env_info.local_done[0]:\n",
    "        break\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
