{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy():\n",
    "\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 256        # minibatch size           # 256 , 512\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4         # learning rate of the actor \n",
    "LR_CRITIC = 3e-4        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0        # L2 weight decay\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc_units=128):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc_units)\n",
    "        self.fc2 = nn.Linear(fc_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        return F.tanh(self.fc2(x))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=128, fc2_units=32, fc3_units=32):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units+action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, fc3_units)\n",
    "        self.fc4 = nn.Linear(fc3_units, 1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "        self.fc4.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        xs = F.leaky_relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0, Episode: 1/250\n",
      "Score: 2, Episode: 2/250\n",
      "Score: 2, Episode: 3/250\n",
      "Score: 14, Episode: 4/250\n",
      "Score: 24, Episode: 5/250\n",
      "Score: 22, Episode: 6/250\n",
      "Score: 1, Episode: 7/250\n",
      "Score: 0, Episode: 8/250\n",
      "Score: 0, Episode: 9/250\n",
      "Score: 0, Episode: 10/250\n",
      "Score: 0, Episode: 11/250\n",
      "Score: 0, Episode: 12/250\n",
      "Score: 1, Episode: 13/250\n",
      "Score: 0, Episode: 14/250\n",
      "Score: 0, Episode: 15/250\n",
      "Score: 2, Episode: 16/250\n",
      "Score: 3, Episode: 17/250\n",
      "Score: 4, Episode: 18/250\n",
      "Score: 4, Episode: 19/250\n",
      "Score: 1, Episode: 20/250\n",
      "Score: 0, Episode: 21/250\n",
      "Score: 1, Episode: 22/250\n",
      "Score: 2, Episode: 23/250\n",
      "Score: 7, Episode: 24/250\n",
      "Score: 9, Episode: 25/250\n",
      "Score: 10, Episode: 26/250\n",
      "Score: 13, Episode: 27/250\n",
      "Score: 18, Episode: 28/250\n",
      "Score: 18, Episode: 29/250\n",
      "Score: 21, Episode: 30/250\n",
      "Score: 16, Episode: 31/250\n",
      "Score: 17, Episode: 32/250\n",
      "Score: 17, Episode: 33/250\n",
      "Score: 16, Episode: 34/250\n",
      "Score: 15, Episode: 35/250\n",
      "Score: 13, Episode: 36/250\n",
      "Score: 11, Episode: 37/250\n",
      "Score: 9, Episode: 38/250\n",
      "Score: 14, Episode: 39/250\n",
      "Score: 17, Episode: 40/250\n",
      "Score: 21, Episode: 41/250\n",
      "Score: 16, Episode: 42/250\n",
      "Score: 19, Episode: 43/250\n",
      "Score: 14, Episode: 44/250\n",
      "Score: 18, Episode: 45/250\n",
      "Score: 14, Episode: 46/250\n",
      "Score: 16, Episode: 47/250\n",
      "Score: 14, Episode: 48/250\n",
      "Score: 9, Episode: 49/250\n",
      "Score: 12, Episode: 50/250\n",
      "Score: 10, Episode: 51/250\n",
      "Score: 12, Episode: 52/250\n",
      "Score: 9, Episode: 53/250\n",
      "Score: 15, Episode: 54/250\n",
      "Score: 19, Episode: 55/250\n",
      "Score: 19, Episode: 56/250\n",
      "Score: 11, Episode: 57/250\n",
      "Score: 15, Episode: 58/250\n",
      "Score: 15, Episode: 59/250\n",
      "Score: 16, Episode: 60/250\n",
      "Score: 15, Episode: 61/250\n",
      "Score: 18, Episode: 62/250\n",
      "Score: 16, Episode: 63/250\n",
      "Score: 18, Episode: 64/250\n",
      "Score: 16, Episode: 65/250\n",
      "Score: 19, Episode: 66/250\n",
      "Score: 20, Episode: 67/250\n",
      "Score: 18, Episode: 68/250\n",
      "Score: 21, Episode: 69/250\n",
      "Score: 22, Episode: 70/250\n",
      "Score: 27, Episode: 71/250\n",
      "Score: 24, Episode: 72/250\n",
      "Score: 23, Episode: 73/250\n",
      "Score: 28, Episode: 74/250\n",
      "Score: 21, Episode: 75/250\n",
      "Score: 25, Episode: 76/250\n",
      "Score: 26, Episode: 77/250\n",
      "Score: 23, Episode: 78/250\n",
      "Score: 26, Episode: 79/250\n",
      "Score: 25, Episode: 80/250\n",
      "Score: 31, Episode: 81/250\n",
      "Score: 25, Episode: 82/250\n",
      "Score: 32, Episode: 83/250\n",
      "Score: 29, Episode: 84/250\n",
      "Score: 22, Episode: 85/250\n",
      "Score: 32, Episode: 86/250\n",
      "Score: 23, Episode: 87/250\n",
      "Score: 27, Episode: 88/250\n",
      "Score: 28, Episode: 89/250\n",
      "Score: 31, Episode: 90/250\n",
      "Score: 29, Episode: 91/250\n",
      "Score: 33, Episode: 92/250\n",
      "Score: 30, Episode: 93/250\n",
      "Score: 34, Episode: 94/250\n",
      "Score: 25, Episode: 95/250\n",
      "Score: 28, Episode: 96/250\n",
      "Score: 28, Episode: 97/250\n",
      "Score: 33, Episode: 98/250\n",
      "Score: 31, Episode: 99/250\n",
      "Score: 31, Episode: 100/250\n",
      "Score: 33, Episode: 101/250\n",
      "Score: 30, Episode: 102/250\n",
      "Score: 36, Episode: 103/250\n",
      "Score: 34, Episode: 104/250\n",
      "Score: 37, Episode: 105/250\n",
      "Score: 38, Episode: 106/250\n",
      "Score: 33, Episode: 107/250\n",
      "Score: 28, Episode: 108/250\n",
      "Score: 33, Episode: 109/250\n",
      "Score: 34, Episode: 110/250\n",
      "Score: 27, Episode: 111/250\n",
      "Score: 32, Episode: 112/250\n",
      "Score: 32, Episode: 113/250\n",
      "Score: 33, Episode: 114/250\n",
      "Score: 39, Episode: 115/250\n",
      "Score: 42, Episode: 116/250\n",
      "Score: 44, Episode: 117/250\n",
      "Score: 43, Episode: 118/250\n",
      "Score: 43, Episode: 119/250\n",
      "Score: 47, Episode: 120/250\n",
      "Score: 37, Episode: 121/250\n",
      "Score: 34, Episode: 122/250\n",
      "Score: 50, Episode: 123/250\n",
      "Score: 40, Episode: 124/250\n",
      "Score: 55, Episode: 125/250\n",
      "Score: 42, Episode: 126/250\n",
      "Score: 38, Episode: 127/250\n",
      "Score: 29, Episode: 128/250\n",
      "Score: 38, Episode: 129/250\n",
      "Score: 37, Episode: 130/250\n",
      "Score: 38, Episode: 131/250\n",
      "Score: 37, Episode: 132/250\n",
      "Score: 37, Episode: 133/250\n",
      "Score: 34, Episode: 134/250\n",
      "Score: 30, Episode: 135/250\n",
      "Score: 34, Episode: 136/250\n",
      "Score: 45, Episode: 137/250\n",
      "Score: 46, Episode: 138/250\n",
      "Score: 42, Episode: 139/250\n",
      "Score: 41, Episode: 140/250\n",
      "Score: 42, Episode: 141/250\n",
      "Score: 42, Episode: 142/250\n",
      "Score: 42, Episode: 143/250\n",
      "Score: 41, Episode: 144/250\n",
      "Score: 43, Episode: 145/250\n",
      "Score: 46, Episode: 146/250\n",
      "Score: 39, Episode: 147/250\n",
      "Score: 45, Episode: 148/250\n",
      "Score: 37, Episode: 149/250\n",
      "Score: 43, Episode: 150/250\n",
      "Score: 38, Episode: 151/250\n",
      "Score: 37, Episode: 152/250\n",
      "Score: 31, Episode: 153/250\n",
      "Score: 39, Episode: 154/250\n",
      "Score: 34, Episode: 155/250\n",
      "Score: 36, Episode: 156/250\n",
      "Score: 35, Episode: 157/250\n",
      "Score: 36, Episode: 158/250\n",
      "Score: 37, Episode: 159/250\n",
      "Score: 42, Episode: 160/250\n",
      "Score: 39, Episode: 161/250\n",
      "Score: 46, Episode: 162/250\n",
      "Score: 51, Episode: 163/250\n",
      "Score: 48, Episode: 164/250\n",
      "Score: 52, Episode: 165/250\n",
      "Score: 51, Episode: 166/250\n",
      "Score: 54, Episode: 167/250\n",
      "Score: 39, Episode: 168/250\n",
      "Score: 48, Episode: 169/250\n",
      "Score: 44, Episode: 170/250\n",
      "Score: 35, Episode: 171/250\n",
      "Score: 48, Episode: 172/250\n",
      "Score: 41, Episode: 173/250\n",
      "Score: 36, Episode: 174/250\n",
      "Score: 38, Episode: 175/250\n",
      "Score: 38, Episode: 176/250\n",
      "Score: 41, Episode: 177/250\n",
      "Score: 36, Episode: 178/250\n",
      "Score: 32, Episode: 179/250\n",
      "Score: 28, Episode: 180/250\n",
      "Score: 30, Episode: 181/250\n",
      "Score: 27, Episode: 182/250\n",
      "Score: 19, Episode: 183/250\n",
      "Score: 25, Episode: 184/250\n",
      "Score: 23, Episode: 185/250\n",
      "Score: 22, Episode: 186/250\n",
      "Score: 20, Episode: 187/250\n",
      "Score: 31, Episode: 188/250\n",
      "Score: 24, Episode: 189/250\n",
      "Score: 11, Episode: 190/250\n",
      "Score: 21, Episode: 191/250\n",
      "Score: 24, Episode: 192/250\n",
      "Score: 28, Episode: 193/250\n",
      "Score: 20, Episode: 194/250\n",
      "Score: 30, Episode: 195/250\n",
      "Score: 37, Episode: 196/250\n",
      "Score: 33, Episode: 197/250\n",
      "Score: 28, Episode: 198/250\n",
      "Score: 41, Episode: 199/250\n",
      "Score: 36, Episode: 200/250\n",
      "Score: 27, Episode: 201/250\n",
      "Score: 34, Episode: 202/250\n",
      "Score: 27, Episode: 203/250\n",
      "Score: 32, Episode: 204/250\n",
      "Score: 45, Episode: 205/250\n",
      "Score: 38, Episode: 206/250\n",
      "Score: 24, Episode: 207/250\n",
      "Score: 43, Episode: 208/250\n",
      "Score: 27, Episode: 209/250\n",
      "Score: 31, Episode: 210/250\n",
      "Score: 35, Episode: 211/250\n",
      "Score: 32, Episode: 212/250\n",
      "Score: 33, Episode: 213/250\n",
      "Score: 31, Episode: 214/250\n",
      "Score: 29, Episode: 215/250\n",
      "Score: 35, Episode: 216/250\n",
      "Score: 27, Episode: 217/250\n",
      "Score: 44, Episode: 218/250\n",
      "Score: 35, Episode: 219/250\n",
      "Score: 27, Episode: 220/250\n",
      "Score: 27, Episode: 221/250\n",
      "Score: 39, Episode: 222/250\n",
      "Score: 26, Episode: 223/250\n",
      "Score: 34, Episode: 224/250\n",
      "Score: 31, Episode: 225/250\n",
      "Score: 31, Episode: 226/250\n",
      "Score: 29, Episode: 227/250\n",
      "Score: 31, Episode: 228/250\n",
      "Score: 44, Episode: 229/250\n",
      "Score: 31, Episode: 230/250\n",
      "Score: 31, Episode: 231/250\n",
      "Score: 33, Episode: 232/250\n",
      "Score: 34, Episode: 233/250\n",
      "Score: 32, Episode: 234/250\n",
      "Score: 34, Episode: 235/250\n",
      "Score: 26, Episode: 236/250\n",
      "Score: 28, Episode: 237/250\n",
      "Score: 32, Episode: 238/250\n",
      "Score: 39, Episode: 239/250\n",
      "Score: 37, Episode: 240/250\n",
      "Score: 34, Episode: 241/250\n",
      "Score: 35, Episode: 242/250\n",
      "Score: 28, Episode: 243/250\n",
      "Score: 26, Episode: 244/250\n",
      "Score: 26, Episode: 245/250\n",
      "Score: 20, Episode: 246/250\n",
      "Score: 20, Episode: 247/250\n",
      "Score: 24, Episode: 248/250\n",
      "Score: 19, Episode: 249/250\n",
      "Score: 23, Episode: 250/250\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30ad0d82b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(state_size=33, action_size=4, random_seed=0)\n",
    "\n",
    "def ddpg(episodes=250, step=1000): # 300 - 600\n",
    "    reward_list = []\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        \n",
    "        env_info = env.reset(train_mode=True)[brain_name]     # reset the environment    \n",
    "        state = env_info.vector_observations\n",
    "        score = 0\n",
    "        #agent.reset()\n",
    "             \n",
    "        for t in range(step):\n",
    "            \n",
    "            action_list = []\n",
    "            for j in range(20):  \n",
    "                action = agent.act(state[[j]])\n",
    "                action_list.append(action)\n",
    "            \n",
    "            actions = np.asarray(action_list)\n",
    "            actions = actions.reshape((20,4))\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_state = env_info.vector_observations\n",
    "            reward = env_info.rewards\n",
    "            done = env_info.local_done\n",
    "            \n",
    "            if t%4 == 0:                            # 2 - 8 \n",
    "                \n",
    "                for k in range(1):                  # 1 or 2\n",
    "                    j = np.random.randint(0,20)\n",
    "                    s1 = state[j].reshape((1,33))\n",
    "                    a = actions[j]\n",
    "                    a = a.reshape((1,4))\n",
    "                    s2 = next_state[j].reshape((1,33))\n",
    "                    r = reward[j]\n",
    "                    agent.step(s1, a, r, s2, done[j])\n",
    "                \n",
    "            state = next_state\n",
    "            score += sum(reward)\n",
    "            \n",
    "            if np.any(done):\n",
    "                break \n",
    "                \n",
    "        reward_list.append(score)\n",
    "        print(\"Score: %d, Episode: %d/%d\" %(score, i+1, episodes))  \n",
    "    \n",
    "    torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "    torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "    return reward_list\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
