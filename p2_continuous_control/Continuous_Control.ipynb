{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy():\n",
    "\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4         # learning rate of the actor \n",
    "LR_CRITIC = 3e-4        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0.0001   # L2 weight decay\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc_units=256):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc_units)\n",
    "        self.fc2 = nn.Linear(fc_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        return F.tanh(self.fc2(x))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=256, fc2_units=256, fc3_units=128):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units+action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, fc3_units)\n",
    "        self.fc4 = nn.Linear(fc3_units, 1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "        self.fc4.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        xs = F.leaky_relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0, Episode: 1/250\n",
      "Score: 5, Episode: 2/250\n",
      "Score: 19, Episode: 3/250\n",
      "Score: 16, Episode: 4/250\n",
      "Score: 21, Episode: 5/250\n",
      "Score: 17, Episode: 6/250\n",
      "Score: 5, Episode: 7/250\n",
      "Score: 1, Episode: 8/250\n",
      "Score: 0, Episode: 9/250\n",
      "Score: 0, Episode: 10/250\n",
      "Score: 0, Episode: 11/250\n",
      "Score: 0, Episode: 12/250\n",
      "Score: 0, Episode: 13/250\n",
      "Score: 0, Episode: 14/250\n",
      "Score: 0, Episode: 15/250\n",
      "Score: 0, Episode: 16/250\n",
      "Score: 0, Episode: 17/250\n",
      "Score: 0, Episode: 18/250\n",
      "Score: 10, Episode: 19/250\n",
      "Score: 8, Episode: 20/250\n",
      "Score: 4, Episode: 21/250\n",
      "Score: 4, Episode: 22/250\n",
      "Score: 1, Episode: 23/250\n",
      "Score: 0, Episode: 24/250\n",
      "Score: 0, Episode: 25/250\n",
      "Score: 20, Episode: 26/250\n",
      "Score: 19, Episode: 27/250\n",
      "Score: 22, Episode: 28/250\n",
      "Score: 18, Episode: 29/250\n",
      "Score: 19, Episode: 30/250\n",
      "Score: 22, Episode: 31/250\n",
      "Score: 24, Episode: 32/250\n",
      "Score: 20, Episode: 33/250\n",
      "Score: 19, Episode: 34/250\n",
      "Score: 19, Episode: 35/250\n",
      "Score: 20, Episode: 36/250\n",
      "Score: 21, Episode: 37/250\n",
      "Score: 22, Episode: 38/250\n",
      "Score: 18, Episode: 39/250\n",
      "Score: 19, Episode: 40/250\n",
      "Score: 26, Episode: 41/250\n",
      "Score: 21, Episode: 42/250\n",
      "Score: 21, Episode: 43/250\n",
      "Score: 18, Episode: 44/250\n",
      "Score: 24, Episode: 45/250\n",
      "Score: 20, Episode: 46/250\n",
      "Score: 21, Episode: 47/250\n",
      "Score: 21, Episode: 48/250\n",
      "Score: 20, Episode: 49/250\n",
      "Score: 20, Episode: 50/250\n",
      "Score: 20, Episode: 51/250\n",
      "Score: 26, Episode: 52/250\n",
      "Score: 18, Episode: 53/250\n",
      "Score: 18, Episode: 54/250\n",
      "Score: 19, Episode: 55/250\n",
      "Score: 22, Episode: 56/250\n",
      "Score: 25, Episode: 57/250\n",
      "Score: 24, Episode: 58/250\n",
      "Score: 19, Episode: 59/250\n",
      "Score: 23, Episode: 60/250\n",
      "Score: 23, Episode: 61/250\n",
      "Score: 19, Episode: 62/250\n",
      "Score: 20, Episode: 63/250\n",
      "Score: 20, Episode: 64/250\n",
      "Score: 20, Episode: 65/250\n",
      "Score: 22, Episode: 66/250\n",
      "Score: 21, Episode: 67/250\n",
      "Score: 20, Episode: 68/250\n",
      "Score: 22, Episode: 69/250\n",
      "Score: 24, Episode: 70/250\n",
      "Score: 16, Episode: 71/250\n",
      "Score: 22, Episode: 72/250\n",
      "Score: 21, Episode: 73/250\n",
      "Score: 20, Episode: 74/250\n",
      "Score: 20, Episode: 75/250\n",
      "Score: 22, Episode: 76/250\n",
      "Score: 19, Episode: 77/250\n",
      "Score: 20, Episode: 78/250\n",
      "Score: 18, Episode: 79/250\n",
      "Score: 18, Episode: 80/250\n",
      "Score: 23, Episode: 81/250\n",
      "Score: 22, Episode: 82/250\n",
      "Score: 18, Episode: 83/250\n",
      "Score: 24, Episode: 84/250\n",
      "Score: 22, Episode: 85/250\n",
      "Score: 20, Episode: 86/250\n",
      "Score: 18, Episode: 87/250\n",
      "Score: 20, Episode: 88/250\n",
      "Score: 21, Episode: 89/250\n",
      "Score: 22, Episode: 90/250\n",
      "Score: 18, Episode: 91/250\n",
      "Score: 18, Episode: 92/250\n",
      "Score: 19, Episode: 93/250\n",
      "Score: 22, Episode: 94/250\n",
      "Score: 23, Episode: 95/250\n",
      "Score: 23, Episode: 96/250\n",
      "Score: 19, Episode: 97/250\n",
      "Score: 19, Episode: 98/250\n",
      "Score: 22, Episode: 99/250\n",
      "Score: 23, Episode: 100/250\n",
      "Score: 18, Episode: 101/250\n",
      "Score: 17, Episode: 102/250\n",
      "Score: 21, Episode: 103/250\n",
      "Score: 17, Episode: 104/250\n",
      "Score: 21, Episode: 105/250\n",
      "Score: 21, Episode: 106/250\n",
      "Score: 22, Episode: 107/250\n",
      "Score: 17, Episode: 108/250\n",
      "Score: 19, Episode: 109/250\n",
      "Score: 21, Episode: 110/250\n",
      "Score: 20, Episode: 111/250\n",
      "Score: 23, Episode: 112/250\n",
      "Score: 25, Episode: 113/250\n",
      "Score: 20, Episode: 114/250\n",
      "Score: 20, Episode: 115/250\n",
      "Score: 19, Episode: 116/250\n",
      "Score: 17, Episode: 117/250\n",
      "Score: 18, Episode: 118/250\n",
      "Score: 21, Episode: 119/250\n",
      "Score: 22, Episode: 120/250\n",
      "Score: 21, Episode: 121/250\n",
      "Score: 25, Episode: 122/250\n",
      "Score: 21, Episode: 123/250\n",
      "Score: 24, Episode: 124/250\n",
      "Score: 23, Episode: 125/250\n",
      "Score: 21, Episode: 126/250\n",
      "Score: 21, Episode: 127/250\n",
      "Score: 17, Episode: 128/250\n",
      "Score: 19, Episode: 129/250\n",
      "Score: 18, Episode: 130/250\n",
      "Score: 16, Episode: 131/250\n",
      "Score: 18, Episode: 132/250\n",
      "Score: 19, Episode: 133/250\n",
      "Score: 19, Episode: 134/250\n",
      "Score: 24, Episode: 135/250\n",
      "Score: 18, Episode: 136/250\n",
      "Score: 17, Episode: 137/250\n",
      "Score: 21, Episode: 138/250\n",
      "Score: 19, Episode: 139/250\n",
      "Score: 20, Episode: 140/250\n",
      "Score: 22, Episode: 141/250\n",
      "Score: 16, Episode: 142/250\n",
      "Score: 18, Episode: 143/250\n",
      "Score: 18, Episode: 144/250\n",
      "Score: 20, Episode: 145/250\n",
      "Score: 21, Episode: 146/250\n",
      "Score: 17, Episode: 147/250\n",
      "Score: 18, Episode: 148/250\n",
      "Score: 22, Episode: 149/250\n",
      "Score: 18, Episode: 150/250\n",
      "Score: 21, Episode: 151/250\n",
      "Score: 21, Episode: 152/250\n",
      "Score: 22, Episode: 153/250\n",
      "Score: 21, Episode: 154/250\n",
      "Score: 16, Episode: 155/250\n",
      "Score: 21, Episode: 156/250\n",
      "Score: 22, Episode: 157/250\n",
      "Score: 23, Episode: 158/250\n",
      "Score: 19, Episode: 159/250\n",
      "Score: 20, Episode: 160/250\n",
      "Score: 23, Episode: 161/250\n",
      "Score: 16, Episode: 162/250\n",
      "Score: 25, Episode: 163/250\n",
      "Score: 21, Episode: 164/250\n",
      "Score: 21, Episode: 165/250\n",
      "Score: 22, Episode: 166/250\n",
      "Score: 16, Episode: 167/250\n",
      "Score: 22, Episode: 168/250\n",
      "Score: 23, Episode: 169/250\n",
      "Score: 22, Episode: 170/250\n",
      "Score: 23, Episode: 171/250\n",
      "Score: 21, Episode: 172/250\n",
      "Score: 22, Episode: 173/250\n",
      "Score: 19, Episode: 174/250\n",
      "Score: 17, Episode: 175/250\n",
      "Score: 20, Episode: 176/250\n",
      "Score: 20, Episode: 177/250\n",
      "Score: 22, Episode: 178/250\n",
      "Score: 24, Episode: 179/250\n",
      "Score: 20, Episode: 180/250\n",
      "Score: 25, Episode: 181/250\n",
      "Score: 24, Episode: 182/250\n",
      "Score: 19, Episode: 183/250\n",
      "Score: 21, Episode: 184/250\n",
      "Score: 17, Episode: 185/250\n",
      "Score: 20, Episode: 186/250\n",
      "Score: 17, Episode: 187/250\n",
      "Score: 22, Episode: 188/250\n",
      "Score: 16, Episode: 189/250\n",
      "Score: 22, Episode: 190/250\n",
      "Score: 17, Episode: 191/250\n",
      "Score: 21, Episode: 192/250\n",
      "Score: 19, Episode: 193/250\n",
      "Score: 19, Episode: 194/250\n",
      "Score: 19, Episode: 195/250\n",
      "Score: 19, Episode: 196/250\n",
      "Score: 22, Episode: 197/250\n",
      "Score: 15, Episode: 198/250\n",
      "Score: 23, Episode: 199/250\n",
      "Score: 21, Episode: 200/250\n",
      "Score: 22, Episode: 201/250\n",
      "Score: 25, Episode: 202/250\n",
      "Score: 20, Episode: 203/250\n",
      "Score: 17, Episode: 204/250\n",
      "Score: 20, Episode: 205/250\n",
      "Score: 19, Episode: 206/250\n",
      "Score: 16, Episode: 207/250\n",
      "Score: 22, Episode: 208/250\n",
      "Score: 19, Episode: 209/250\n",
      "Score: 25, Episode: 210/250\n",
      "Score: 22, Episode: 211/250\n",
      "Score: 22, Episode: 212/250\n",
      "Score: 19, Episode: 213/250\n",
      "Score: 19, Episode: 214/250\n",
      "Score: 22, Episode: 215/250\n",
      "Score: 21, Episode: 216/250\n",
      "Score: 20, Episode: 217/250\n",
      "Score: 18, Episode: 218/250\n",
      "Score: 23, Episode: 219/250\n",
      "Score: 19, Episode: 220/250\n",
      "Score: 20, Episode: 221/250\n",
      "Score: 19, Episode: 222/250\n",
      "Score: 20, Episode: 223/250\n",
      "Score: 21, Episode: 224/250\n",
      "Score: 24, Episode: 225/250\n",
      "Score: 14, Episode: 226/250\n",
      "Score: 26, Episode: 227/250\n",
      "Score: 21, Episode: 228/250\n",
      "Score: 19, Episode: 229/250\n",
      "Score: 21, Episode: 230/250\n",
      "Score: 19, Episode: 231/250\n",
      "Score: 21, Episode: 232/250\n",
      "Score: 20, Episode: 233/250\n",
      "Score: 27, Episode: 234/250\n",
      "Score: 22, Episode: 235/250\n",
      "Score: 20, Episode: 236/250\n",
      "Score: 15, Episode: 237/250\n",
      "Score: 22, Episode: 238/250\n",
      "Score: 18, Episode: 239/250\n",
      "Score: 19, Episode: 240/250\n",
      "Score: 19, Episode: 241/250\n",
      "Score: 18, Episode: 242/250\n",
      "Score: 20, Episode: 243/250\n",
      "Score: 21, Episode: 244/250\n",
      "Score: 20, Episode: 245/250\n",
      "Score: 23, Episode: 246/250\n",
      "Score: 22, Episode: 247/250\n",
      "Score: 19, Episode: 248/250\n",
      "Score: 21, Episode: 249/250\n",
      "Score: 18, Episode: 250/250\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c60a24940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(state_size=33, action_size=4, random_seed=0)\n",
    "\n",
    "def ddpg(episodes=250, step=1000):\n",
    "    reward_list = []\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        \n",
    "        env_info = env.reset(train_mode=True)[brain_name]     # reset the environment    \n",
    "        state = env_info.vector_observations\n",
    "        score = 0\n",
    "             \n",
    "        for t in range(step):\n",
    "            \n",
    "            action_list = []\n",
    "            for j in range(20):  \n",
    "                action = agent.act(state[[j]])\n",
    "                action_list.append(action)\n",
    "            \n",
    "            actions = np.asarray(action_list)\n",
    "            actions = actions.reshape((20,4))\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_state = env_info.vector_observations\n",
    "            reward = env_info.rewards\n",
    "            done = env_info.local_done\n",
    "            \n",
    "            if t%5 == 0:\n",
    "                \n",
    "                for k in range(1):\n",
    "                    j = np.random.randint(0,20)\n",
    "                    s1 = state[j].reshape((1,33))\n",
    "                    a = actions[j]\n",
    "                    a = a.reshape((1,4))\n",
    "                    s2 = next_state[j].reshape((1,33))\n",
    "                    r = reward[j]\n",
    "                    agent.step(s1, a, r, s2, done[j])\n",
    "                \n",
    "            state = next_state\n",
    "            score += sum(reward)\n",
    "            \n",
    "            if np.any(done):\n",
    "                break \n",
    "                \n",
    "        reward_list.append(score)\n",
    "        print(\"Score: %d, Episode: %d/%d\" %(score, i+1, episodes))  \n",
    "    \n",
    "    torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "    torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "    return reward_list\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
